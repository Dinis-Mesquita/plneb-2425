{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51522cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_in = open(\"dataset_articles.json\")\n",
    "\n",
    "papers = json.load(file_in)\n",
    "\n",
    "def filter_papers(papers):\n",
    "    res=[]\n",
    "    for paper in papers:\n",
    "        if paper[\"abstract\"] and len(paper[\"abstract\"]) > 150 and len(paper[\"keywords\"]) not in [None,\".\"]:\n",
    "            res.append(paper)\n",
    "\n",
    "    return res\n",
    "\n",
    "fi_papers = filter_papers(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb91bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import re\n",
    "pares=[]\n",
    "\n",
    "\n",
    "def proc_keywords(keywords_s):\n",
    "    keywords_s = keywords_s.lower().strip()\n",
    "    keywords_s = re.sub(r\"\\\\/\",\"/\",keywords_s)\n",
    "    keywords=re.split(r\"[,;/]\",keywords_s)\n",
    "    return [keywords.strip() for keyword in keywords]\n",
    "\n",
    "\n",
    "#gerar pares\n",
    "for paper1,paper2 in combinations(fi_papers,2):\n",
    "    key1,key2 = proc_keywords(paper1[\"keywords\"]), proc_keywords(paper2[\"keywords\"])\n",
    "    score = len(set(key1) & set(key2)) #intersecao, mas so é possivel em sets\n",
    "    pares.append((paper1[\"abstract\"],paper2[\"abstract\"],score)) #é um tuplo\n",
    "\n",
    "#pares[:10]\n",
    "len(pares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac651ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([score for _,_,score in pares])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaccace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#balancear dados\n",
    "majority_class = [(a1, a2, score) for a1, a2, score in pares if score ==0]\n",
    "minority_class = [(a1, a2, score) for a1, a2, score in pares if score !=0]\n",
    "\n",
    "undersampled_majority_class = resample(majority_class,\n",
    "                                       replace=False #Dont duplicate samples\n",
    "                                       n_samples = len(minortiy_class), #match minority\n",
    "                                       random_state=42)\n",
    "\n",
    "balanced_pairs = undersampled_majority_class + minority_class\n",
    "\n",
    "Counter([score for _,_,score in balanced_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(score):\n",
    "    if score == 1:\n",
    "        return 0.5\n",
    "    elif score ==2:\n",
    "        return 0.7\n",
    "    elif score >= 3:\n",
    "        return 0.9\n",
    "    \n",
    "    elif score ==0:\n",
    "        return 0\n",
    "    \n",
    "balanced_pairs = [(a1,a2,normalize_scores(s)) for a1, a2, s in balanced_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dac7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scores = [score for _, _, score in balanced_pairs]\n",
    "train_data, test_data = train_test_split(\n",
    "    balanced_pairs,\n",
    "    test_size=2,\n",
    "    random_state=42,\n",
    "    stratify=scores\n",
    ")\n",
    "\n",
    "\n",
    "Counter([score for _,_,score in train_data])\n",
    "\n",
    "Counter([score for _,_,score in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sbert.net/docs/sentence_transformer/training_overview.html\n",
    "from datasets import Dataset\n",
    "def create_dataset(pairs):\n",
    "    res = {\n",
    "        \"abstracts1\"=[],\n",
    "        \"abstracts2\" = [],\n",
    "        \"score\"=[]\n",
    "    }\n",
    "\n",
    "    for a1, a2, scores in pairs:\n",
    "        res[\"abstracts1\"].append(a1)\n",
    "        res[\"abstracts2\"].append(a2)\n",
    "        res[\"scores\"].append(scores)\n",
    "\n",
    "    return res\n",
    "test_dt = Dataset.from_dict(create_dataset(test_data))\n",
    "train_dt = Dataset.from_dict(create_dataset(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import CoSENTLoss\n",
    "\n",
    "# Load a model to train/finetune\n",
    "model = SentenceTransformer(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "# Initialize the CoSENTLoss\n",
    "# This loss requires pairs of text and a float similarity score as a label\n",
    "loss = losses.CosineSimilarityLoss(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b756e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.similarity_functions  import SimilarityFunction\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/aula\" ,\n",
    "    report_to=\"none\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e2c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create evaluator\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    test_dataset['abstract1'],  # Assuming these are the sentence pairs for evaluation\n",
    "    test_dataset['abstract2'],\n",
    "    test_dataset['score'],  # Assuming this contains the similarity scores\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4694db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"models/aula\") #buscar o modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [paper[\"abstracts\"] for paper in fi_papers]\n",
    "\n",
    "titles = [paper[\"title\"] for paper in fi_papers]\n",
    "keywords = [paper[\"keywords\"] for paper in fi_papers]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f3da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import torch\n",
    "embeddings = model.encode(abstracts, convert_to_tensor=True)\n",
    "query_embedding = model.encode(query_text, convert_to_tensor=True)\n",
    "# Calculate the similarity between the query and the abstracts\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding, embeddings)\n",
    "retrieval_results = torch.topk(cosine_scores, k=15)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
